{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6b7d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed64053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1d29eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b91f559f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Ana\\envs\\hw4q3try3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2888\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2889\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2890\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-93867a903899>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;31m#print(\"y Test is :\" + str(i) + \" y Predict is:\" + y_predict_test[i])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predict_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"1.0\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my_predict_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;34m\"1\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Ana\\envs\\hw4q3try3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m         if (\n",
      "\u001b[1;32mC:\\Ana\\envs\\hw4q3try3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 991\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    992\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Ana\\envs\\hw4q3try3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2890\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2891\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2893\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import gc\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, average_precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "\n",
    "\n",
    "dis_path = './data/us_disaster_declarations.csv'\n",
    "temp_path = './data/GlobalLandTemperaturesByState.csv'\n",
    "states_path = './data/states.csv'\n",
    "\n",
    "# load list of states\n",
    "states = {}\n",
    "with open(states_path) as f:\n",
    "    next(f)\n",
    "\n",
    "    for line in f:\n",
    "        l = line.split(',')\n",
    "        states[l[0].strip()] = l[1].strip()\n",
    "\n",
    "# print(states)\n",
    "\n",
    "# filter disaster dataset\n",
    "dis_data = pd.read_csv(dis_path)[['state', 'declaration_date', 'incident_type','declaration_title']].rename({'declaration_date': 'date'}, axis=1)\n",
    "dis_data['date'] = dis_data['date'].astype('datetime64[ns]').dt.strftime('%m-%Y')\n",
    "dis_data = dis_data.drop_duplicates(subset=['incident_type', 'declaration_title', 'date', 'state'], keep='first')\n",
    "# dis_data = dis_data.groupby(['state', 'date']).count()\n",
    "dis_data['disaster_type'] = dis_data['incident_type']\n",
    "dis_data = dis_data.rename({'incident_type': 'disaster_occurrence'}, axis=1)\n",
    "dis_data['disaster_occurrence'] = np.ones(dis_data['disaster_occurrence'].shape)\n",
    "# dis_data = dis_data.reset_index()\n",
    "\n",
    "# print(dis_data)\n",
    "\n",
    "dis_data.to_csv('./data/test_disasters_state_month.csv', index=False)\n",
    "\n",
    "# filter temperature dataset\n",
    "temp_data = pd.read_csv(temp_path)\n",
    "temp_data = temp_data[temp_data['Country'] == 'United States'].dropna()  # filter by United States, remove NaNs\n",
    "temp_data['date'] = temp_data['dt'].astype('datetime64[ns]').dt.strftime('%m-%Y')  # convert string to date, then convert to year\n",
    "temp_data['state'] = temp_data['State'].apply(lambda x: states[x] if x in states else None)  # preprocess state strings\n",
    "temp_data = temp_data.dropna()\n",
    "temp_data = temp_data.groupby(['date', 'state'])  # group by year then state\n",
    "temp_data = temp_data[['AverageTemperature', 'AverageTemperatureUncertainty']].mean().reset_index()  # take average over groups\n",
    "\n",
    "# print(temp_data)\n",
    "\n",
    "temp_data.to_csv('./data/test_temp_state_month.csv', index=False)\n",
    "\n",
    "# join on `Year` and `State`\n",
    "df = pd.merge(temp_data, dis_data, on=['date', 'state'], how='left').set_index(['date', 'state'], drop=True)\n",
    "df.rename({'AverageTemperature': 'ave_temp', 'AverageTemperatureUncertainty': 'ave_temp_uncertainty'}, axis=1, inplace=True)\n",
    "df = df.fillna(0).reset_index()\n",
    "df['month'] = df['date'].astype('datetime64[ns]').dt.strftime('%m')\n",
    "df['year'] = df['date'].astype('datetime64[ns]').dt.strftime('%Y')\n",
    "df['date'] = pd.to_datetime(df.date)\n",
    "\n",
    "\n",
    "df.to_csv('./data/test_disasters_temp_state_month.csv', index=False)\n",
    "\n",
    "df['y_data'] = df['disaster_occurrence']\n",
    "df = df.drop(['disaster_occurrence'], axis=1)\n",
    "\n",
    "\n",
    "df = df[df.year > \"1960\"]\n",
    "df = df.drop(['year'], axis=1)\n",
    "\n",
    "df = df.sort_values(by=['date'])\n",
    "x_data = df.iloc[:,0:-1]\n",
    "y_data = df.iloc[:,-1]\n",
    "\n",
    "df = df.drop(['declaration_title','disaster_type'], axis=1)\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, train_size=.5, shuffle=False)\n",
    "\n",
    "train_rows = int(0.6 * x_data.shape[0])\n",
    "test_rows = x_data.shape[0] - train_rows# - train_rows\n",
    "\n",
    "x_train = df.iloc[:train_rows, 0:-1]\n",
    "y_train = df.iloc[:train_rows, -1]\n",
    "x_test = df.iloc[train_rows:, 0:-1]\n",
    "y_test = df.iloc[train_rows:, -1]\n",
    "    \n",
    "X = x_data.iloc[:,2:]\n",
    "y = y_data\n",
    "\n",
    "x_test_plot = x_test.iloc[:,2:]\n",
    "\n",
    "logR = LogisticRegression()\n",
    "logR.fit(x_train.iloc[:,2:], y_train)\n",
    "y_predict_test = logR.predict_proba(x_test.iloc[:,2:])\n",
    "y_predict_train = logR.predict_proba(x_train.iloc[:,2:])\n",
    "\n",
    "y_predict_test = y_predict_test[:,1:]\n",
    "\n",
    "\n",
    "logResgressionPerTestCombined.to_csv('./data/logResgressionPerTestCombined.csv', index=False)                        \n",
    "test_actual.to_csv('./data/test_actual.csv', index=False)\n",
    "LogisticRegression_Test_Per.to_csv('./data/logRPredictTest.csv', index=False)    \n",
    "\n",
    "y_predict_test_no_prob = np.where(y_predict_test >= .1, 1, 0)\n",
    "\n",
    "count = 0\n",
    "for i in range (0, len(y_test)):\n",
    "    #print(\"y Test is :\" + str(i) + \" y Predict is:\" + y_predict_test[i])\n",
    "    print(y_test[i])\n",
    "    print(y_predict_test[i])\n",
    "    if y_test[i] == \"1.0\" and y_predict_test[i] ==\"1\":\n",
    "        count = count +1\n",
    "print(count)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_predict_test_no_prob)\n",
    "test_avg_pers = average_precision_score(y_test, y_predict_test_no_prob)\n",
    "\n",
    "\n",
    "disp = plot_precision_recall_curve(logR, x_test_plot, y_test)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(test_avg_pers))\n",
    "\n",
    "\n",
    "x_test['Disaster_Prob'] = y_predict_test\n",
    "x_test['y_data'] = y_data\n",
    "\n",
    "\n",
    "test_df = pd.DataFrame(y_predict_test, columns = ['Y_predict'])\n",
    "\n",
    "\n",
    "test_actual = df.iloc[test_rows:,:]\n",
    "\n",
    "test_actual=test_actual[['date', 'state', 'y_data']]\n",
    "LogisticRegression_Test_Per = x_test[['date', 'state', 'Disaster_Prob']]\n",
    "logResgressionPerTestCombined = x_test[['date', 'state', 'Disaster_Prob', 'y_data']]\n",
    "\n",
    "print(test_accuracy)\n",
    "print(test_avg_pers)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3a7b005d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.95494471 0.04505529]\n",
      " [0.84495342 0.15504658]\n",
      " [0.82706004 0.17293996]\n",
      " ...\n",
      " [0.907349   0.092651  ]\n",
      " [0.95457925 0.04542075]\n",
      " [0.82788755 0.17211245]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "def split_data(X, y, test_size = 0.2):       \n",
    "    import sklearn as sk    \n",
    "    return sk.model_selection.train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(X, y, test_size = 0.2)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB    \n",
    "GNBclf = GaussianNB()\n",
    "classfier = GNBclf.fit(X_train, y_train)\n",
    "\n",
    "def score_and_predict(classifier, X_train, y_train, X_test, y_test):    \n",
    "    y_Train_pred = classifier.predict_proba(X_train)\n",
    "    y_Test_pred = classifier.predict_proba(X_test)\n",
    "    #testing_score = metrics.accuracy_score(y_test, y_Test_pred)\n",
    "    #training_score = metrics.accuracy_score(y_train, y_Train_pred)\n",
    "    return y_Train_pred\n",
    "\n",
    "y_pred = score_and_predict(classfier, X_train, y_train, X_test, y_test)\n",
    "#print('Mean accuracy on training data = {} and testing data = {}'.format(training_score.round(2), testing_score.round(2)))\n",
    "print(y_pred)\n",
    "def print_classification_report(y_test, y_pred):       \n",
    "    from sklearn.metrics import classification_report\n",
    "    return (print(classification_report(y_test,y_pred)))\n",
    "\n",
    "#print_classification_report(y_test, y_pred)\n",
    "\n",
    "def roc_curve(classifier, X_test, y_test):      \n",
    "    from sklearn.metrics import roc_curve\n",
    "    import matplotlib.pyplot as plt       \n",
    "    predict_prob = classifier.predict_proba(X_test)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test,predict_prob[:, 1])\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')        \n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')   \n",
    "    return (plt.show())\n",
    "\n",
    "#roc_curve(classifier, X_test, y_test)\n",
    "from sklearn.svm import SVC\n",
    "SVMclf = SVC(probability=True) \n",
    "SVMclf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-species",
   "metadata": {},
   "source": [
    "# 1. Setting up a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-standing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "with open('data_test.csv', 'r') as file:\n",
    "    df = csv.reader(file)\n",
    "    for row in df:\n",
    "        print(row)\n",
    "        \n",
    "df = pd.read_csv('data_test.csv')\n",
    "        \n",
    "#Create the confusion matrix\n",
    "# Importing the dependancies\n",
    "\n",
    "y_pred = df[df.columns[-1]]\n",
    "# Actual values\n",
    "y_act = df[df.columns[2]]\n",
    "\n",
    "# Printing the confusion matrix\n",
    "# The columns will show the instances predicted for each label,\n",
    "# and the rows will show the actual number of instances for each label.\n",
    "\n",
    "print(y_pred)\n",
    "# Printing the precision and recall, among other metrics\n",
    "\n",
    "print(y_act)\n",
    "#confusion matrix\n",
    "print(metrics.confusion_matrix(y_act, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-winning",
   "metadata": {},
   "source": [
    "# 2. Finding other useful model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#other model metrics\n",
    "print(metrics.classification_report(y_act, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-ferry",
   "metadata": {},
   "source": [
    "# 3. Create an ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#Computing the ROC curve\n",
    "n_classes = y_act.shape[0]\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_act[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_act.ravel(), y_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "#Plotting the ROC curve\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-clothing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
